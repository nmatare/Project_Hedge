<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>output: rticles::elsevier_article</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<!-- rmarkdown v1 -->

<hr/>

<p>title: Mimicing S&amp;P 500 Returns via eGARCH and DCC models
author:</p>

<ul>
<li>name: Nathan Matare</li>
</ul>

<p>address:</p>

<ul>
<li>code: 
address: The University of Chicago Booth School of Business</li>
<li>code: Another University
address: <a href="mailto:nmatare@chicagobooth.edu">nmatare@chicagobooth.edu</a></li>
</ul>

<p>abstract: |
  Create a portfolio that best mimics the monthly returns of the S&amp;P 500 Index over the past 10 years and does not hold more than 10 securities at any one time. Securities may consist of individual company stocks and not funds or any other type of investment vehicle.</p>

<h2>output: rticles::elsevier_article</h2>

<h1>Methodology</h1>

<p>I will mimic the daily returns of the S&amp;P 500 by isolating my universe of potential secruities to stocks currently listed on the S&amp;P 500 and by holding equal weights in the ten-most correlated secruites. This is a non-trivial task. In order to isolate and identify such secruites, I outline five steps:</p>

<ol>
<li>Collect daily stock level prices on S&amp;P 500 secruities</li>
<li>Clean and pre-process data</li>
<li>Estimate time varying conditional correlation via eGARCH and DCC models</li>
<li>Isolate the top-ten most correlated secruites and form a daily profolio</li>
<li>Compare profolio returns to S&amp;P 500 returns</li>
</ol>

<h1>Collect Daily Price Levels</h1>

<p>I begin by compiling a list of all stocks currrently listed on the S&amp;P 500. These stocks will constitute my &#39;universe&#39; of secruities. In order to expediate the data collection process, I write a function &ldquo;SecruityScraper&rdquo;<sup>[See</sup> appendix for additional information] to scrape daily price level data for the past 10 years.<sup>[See</sup> <a href="https://www.quandl.com/data/WIKI">Quandl</a> datasets]</p>

<pre><code class="r">enddate &lt;- Sys.Date()
startdate &lt;- enddate - 365*10 
source(&quot;secruityscraper.R&quot;)
SecruityScraper(name=&quot;SP500&quot;, 
                startdate=startdate, 
                enddate=enddate, type=&quot;WIKI&quot;, 
                key=&quot;X&quot;, sleep=0)
</code></pre>

<h1>Collect Daily Price Levels</h1>

<p>Because the raw data contains weekends, holidays, and missing observations it is necessary to clean and preprocess the data in order to faciliate smooth analysis. I write another function, &ldquo;SecruityCleaner&rdquo;<sup>[See</sup> appendix for additional information] to clean the raw datasets. <sup>[Missing</sup> observations are imputed with either the nearest column value or column mean, depedent on the situation] </p>

<pre><code class="r">source(&quot;secruitycleaner.R&quot;)
SecruityCleaner(name=&quot;SP500&quot;, days=144)
</code></pre>

<p>During this step, I also append daily S&amp;P 500 price levels so that I may compare final results. </p>

<pre><code class="r">sp &lt;- Quandl(&quot;YAHOO/INDEX_GSPC&quot;, 
             start_date=startdate, 
             end_date=enddate)

#match SP levels to clean dataset
rows &lt;- match(as.character(sp[,1]),
              as.character(raw[,1])) 

#append S&amp;P 500 to vector 
raw$SP500 &lt;- sp[,2] 
</code></pre>

<p>Now that the data has my universe of clean secruities and S&amp;P 500 price levels, I further manipulate that data by taking the natural log of all price series. This gives the added benfit of being able to take continously compounded returns. I also create a secondary data frame that holds the returns of each secruity. </p>

<pre><code class="r">#Convert data to log level and take difference
data &lt;- data.frame(apply(raw[,-1], MARGIN=2, log)) 
data$Date &lt;- as.character(dates)

#Difference log prices to find returns 
rtrn &lt;- data.frame(apply(data[,-dim(data)[2]], MARGIN=2, diff)) 
rtrn$Date &lt;- as.character(dates[-1])
rownames(rtrn) &lt;- sp$Date[-1]
</code></pre>

<h1>Analysis: Conditional Correlations</h1>

<p>Discussion of the analysis you are going to run</p>

<p>I first create a parallel environment to speed up computation</p>

<pre><code class="r">library(parallel)
cl &lt;- makeCluster(min(detectCores(),5),
      type=ifelse(.Platform$OS.type==&quot;unix&quot;,&quot;FORK&quot;,&quot;PSOCK&quot;))
setwd(datdir)
</code></pre>

<p>Next I load the specifications for my GARCH varaince</p>

<p>Talk about diagnosistics
import historgram of residuals 
talk about skew and kurtosis</p>

<blockquote>
<p>hist(moddata[,1])gj
kurtosis(moddata[,1])</p>
</blockquote>

<pre><code class="r">library(rmgarch)
require(rugarch)

#Build parameters for market GARCH
spec1 &lt;- ugarchspec(variance.model = 
                    list(model = &quot;gjrGARCH&quot;, 
                    garchOrder = c(2,2)), distribution.model= &quot;std&quot;)

#Build parameters for secruity GARCH
spec2 &lt;- ugarchspec(variance.model = 
                    list(model = &quot;gjrGARCH&quot;, 
                    garchOrder = c(1,1)), distribution.model= &quot;std&quot;)
</code></pre>

<p>If the document class <em>elsarticle</em> is not available on your computer,
you can download and install the system package <em>texlive-publishers</em>
(Linux) or install the LaTeX package <em>elsarticle</em> using the package
manager of your TeX installation, which is typically TeX Live or MikTeX.</p>

<h4>Usage</h4>

<p>Once the package is properly installed, you can use the document class
<em>elsarticle</em> to create a manuscript. Please make sure that your
manuscript follows the guidelines in the Guide for Authors of the
relevant journal. It is not necessary to typeset your manuscript in
exactly the same way as an article, unless you are submitting to a
camera-ready copy (CRC) journal.</p>

<h4>Functionality</h4>

<p>The Elsevier article class is based on the standard article class and
supports almost all of the functionality of that class. In addition, it
features commands and options to format the</p>

<ul>
<li><p>document style</p></li>
<li><p>baselineskip</p></li>
<li><p>front matter</p></li>
<li><p>keywords and MSC codes</p></li>
<li><p>theorems, definitions and proofs</p></li>
<li><p>lables of enumerations</p></li>
<li><p>citation style and labeling.</p></li>
</ul>

<h1>Front matter</h1>

<p>The author names and affiliations could be formatted in two ways:</p>

<p>(1) Group the authors per affiliation.</p>

<p>(2) Use footnotes to indicate the affiliations.</p>

<p>See the front matter of this document for examples. You are recommended
to conform your choice to the journal you are submitting to.</p>

<h1>Appendix</h1>

<pre><code class="r">SecruityScraper &lt;- function(name, startdate, enddate, type, key, sleep){

# Description
# This script scraps Quandl.com for data given a date range and symbol list

# Arguments

#&#39;name&#39; is the name of a csv file containing stock symbols to download #do not include .csv
#&#39;startdate&#39; is the start date of data
#&#39;enddate&#39; is the end data of data
#&#39;type&#39; is the Quandl database header; this should be input as a character  IE &#39;WIKI&#39;
#&#39;key&#39; is the Quandl key
#&#39;sleep&#39; is the number of seconds to wait before querying Quandl server

# Example
# SecruityScraper(&quot;NASDAQ&quot;, &quot;2001-09-11&quot;, &quot;2015-01-01&quot;, &quot;WIKI&quot;,&quot;40F..U&amp;E&quot;)

# Requirements

# Requires the Quandl library
# Requires loaded csv file to have a column header of &quot;ticker&quot; for all secruity symbols
# Startdate and enddate must not be same date

#setup environment
name &lt;- name
raw &lt;- read.csv(paste(name,&quot;.csv&quot;, sep=&#39;&#39;))
tickers &lt;- as.character(raw$ticker)

enddate &lt;- enddate
startdate &lt;- startdate
dates &lt;- seq.Date(as.Date(startdate), as.Date(enddate), by=&#39;day&#39;) #create daily dates

#allocate memory for data
L &lt;- length(tickers)
D &lt;- length(dates) 
dataset &lt;- matrix(ncol=L, nrow=D)
dimnames(dataset) &lt;- list(rownames(dataset, 
                                   do.NULL = FALSE, 
                                   prefix = &quot;row&quot;), 
                                   colnames(dataset, 
                                   do.NULL = FALSE, 
                                   prefix = &quot;col&quot;))
colnames(dataset) &lt;- tickers
rownames(dataset) &lt;- as.character(dates)

#specify date range
enddate &lt;- dates[length(dates)]
startdate &lt;- dates[1]
header &lt;- paste(type, &quot;/&quot;, sep=&quot;&quot;)

#retrive stock data
require(Quandl)
Quandl.api_key(key)

for(i in 1:L){

tryCatch({
sym &lt;- paste(header, tickers[i], sep=&quot;&quot;)
info &lt;- Quandl(sym, start_date=startdate, end_date=enddate)
tempdate &lt;- info$Date

info &lt;- data.frame(info$Close)
rownames(info) &lt;- tempdate
put &lt;- merge(info, dataset[,i], by=0, all=TRUE)
dataset[,i] &lt;- put$info.Close
message(&quot;Scraping data for stock: &quot;, tickers[i], &quot; | Number: &quot;, i, &quot;/&quot;, L)

Sys.sleep(sleep) #API speed limit 
}, error=function(e)    {
cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\n&quot;)
#Last value throws error
})

}

#export data 
write.csv(dataset, file = paste(name,&quot;-output.csv&quot;, sep=&#39;&#39;))

}


# Utility script for Secruity Cleaner 
remove_outliers &lt;- function(x, na.rm = TRUE, ...) {
  qnt &lt;- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H &lt;- 1.5 * IQR(x, na.rm = na.rm)
  y &lt;- x
  y[x &lt; (qnt[1] - H)] &lt;- NA
  y[x &gt; (qnt[2] + H)] &lt;- NA
  y
}
</code></pre>

<pre><code class="r">SecruityCleaner &lt;- function(name, days){

# Description
# This utility script removes non-trading days from SecruityScraper and imputes missing values with the nearest value 

# Arguments
#&#39;name&#39; is the name of a csv file containing stock symbols to download #do not include .csv
#&#39;days&#39; is the number of expected non-trading days per average year, default is 144

# Example
# SecruityCleaner(&quot;NASDAQ&quot;, 144)

# Requirements

# Requires the zoo library

# Other

# Error &quot;ERROR(expected) : undefined columns selected&quot; is excpected as columns are removed and length of for-loop does not dynamically change

#setup environment
raw &lt;- read.csv(paste(name,&quot;-output.csv&quot;, sep=&#39;&#39;))
colnames(raw)[colnames(raw)==&quot;X&quot;] &lt;- &quot;date&quot;
L &lt;- length(raw)

# take out the non trading days aka weekends and holidays
narows &lt;- as.numeric(rownames(raw[rowSums(is.na(raw))&gt;=dim(raw)[2]-10,])) 
raw &lt;- raw[-narows,]
U &lt;- dim(raw)[1]/365*(days-3) #number of years worth of data * number of non-trading days = max expected NAs #where 3 is a buffer
L &lt;- length(raw)

#Remove secruites with missing observations
for(n in 2:(L-1)){

  tryCatch({
        if (sum(is.na(raw[,n])) &lt; U) {
                        message(&quot;Pass: &quot;, n)
        } else {
                      message(&quot;Remove (not enough observations): &quot;, n)
                        raw &lt;- raw[,-c(n)]
        }
    }, error=function(e)    {#as columns are strunk, n becomes larger than initial column number set and produces errors at the end
    cat(&quot;ERROR(expected) :&quot;,conditionMessage(e), &quot;\n&quot;)
    })

}

require(zoo)
L &lt;- length(raw)
end &lt;- dim(raw)[1]

#Impute missing price levels with nearest price level
for(n in 2:L){

raw[1,n] &lt;- ifelse(is.na(raw[1,n])==TRUE, na.locf(raw[,n])[1], raw[1,n]) #place value in first 
raw[end,n] &lt;- ifelse(is.na(raw[end,n])==TRUE, na.locf(raw[,n])[end], raw[end,n]) #place value in last
raw[,n] &lt;- na.locf(raw[,n] ,fromlast=TRUE) # scrub NA from backwards
message(&quot;Imputing missing values with nearest value: &quot;, n)

}

#Remove outliers and replace them with mean
L &lt;- length(raw)
for(n in 2:L){
            removed &lt;- remove_outliers(raw[,n])
            removed[is.na(removed)] = mean(removed, na.rm=TRUE)
            raw[,n] &lt;- removed
            message(&quot;Removing outliers and imputing with mean: &quot;, n)
            }

write.csv(raw, file = paste(name,&quot;-output-clean.csv&quot;, sep=&#39;&#39;))

}
</code></pre>

</body>

</html>

